{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Data-on-MDT Requirements\n",
    "\n",
    "Uses an empirically derived file size distribution to project how much Data-on-MDT capacity would be required for a future Lustre file system of arbitrary size.\n",
    "\n",
    "This analysis assumes all non-file inodes have a minimum size given by `LUSTRE_BYTES_PER_INODE`.  This is a reasonable but conservative estimate.  Our choice of `LUSTRE_BYTES_PER_INODE` here is 4 KiB, which is\n",
    "\n",
    "1. probably an over-estimate for ldiskfs; modern Lustre versions default to something closer to 2.5 KiB\n",
    "2. sufficient for zfs, as ZFS triplicates metadata\n",
    "\n",
    "Note that at the block level, inodes are rounded up to a full block allocation (4 KiB) and the efficiency with which Lustre utilizes that allocated block depends on what features are in use to pack blocks.  Capturing these nuances in the following model is over-precise given the inaccuracy intrinsic to the simplicity of the mode, so we just wrap everything into the above assumption about `LUSTRE_BYTES_PER_INODE`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sqlite3\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.rcParams['font.size'] = 16\n",
    "import matplotlib.pyplot\n",
    "import pandas\n",
    "import numpy\n",
    "import fsanalysis.histogram as histogram\n",
    "\n",
    "TO_BYTE = 1\n",
    "TO_KIB = 2**(-10)\n",
    "TO_MIB = 2**(-20)\n",
    "TO_GIB = 2**(-30)\n",
    "TO_TIB = 2**(-40)\n",
    "TO_PIB = 2**(-50)\n",
    "\n",
    "# The SQLite database containing the file size distribution\n",
    "# INPUT_DB_FILE = 'datasets/cscratch_20181109_sizebytype.sqlite'\n",
    "INPUT_DB_FILE = 'datasets/cscratch_20190115_sizebytype.sqlite'\n",
    "INPUT_DB_DATE = INPUT_DB_FILE.split('_')[1]\n",
    "\n",
    "TARGET_TOTAL_OST_CAPACITY = 30.0 / TO_PIB\n",
    "# for reference, cscratch is formatted for 1.5 KiB/inode on master MDT; 3.5 KiB/inode for secondaries\n",
    "LUSTRE_BYTES_PER_INODE = 4.0 / TO_KIB\n",
    "\n",
    "# Types of inodes in our dataframe\n",
    "INODE_TYPES = ['files', 'dirs', 'symlinks', 'blks', 'chrs', 'fifos', 'socks']\n",
    "\n",
    "# we have to distinguish file inodes from non-file inodes because file inodes' \"size\"\n",
    "# is the size of the file rather than the size of the inode.  all other inodes' \"size\"\n",
    "# is the size they take up on the MDT.\n",
    "NON_FILE_INODE_TYPES = INODE_TYPES[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def humanize_units(bytect):\n",
    "    \"\"\"Helper function to convert bytes into base-2 units\"\"\"\n",
    "    for units in [(2**50, \"PiB\"), (2**40, \"TiB\"), (2**30, \"GiB\"), (2**20, \"MiB\"), (2**10, \"KiB\")]:\n",
    "        if bytect >= units[0]:\n",
    "            return bytect / units[0], units[1]\n",
    "\n",
    "    return bytect, \"bytes\" if bytect != 1 else \"byte\"\n",
    "\n",
    "def humanize_units_generic_base10(count):\n",
    "    \"\"\"Helper function to convert counts into base-10 units\"\"\"\n",
    "    for units in [(10.0**12, \"T\"), (10.0**9, \"B\"), (10.0**6, \"M\"), (10.0**3, \"K\")]:\n",
    "        if count >= units[0]:\n",
    "            return count / units[0], units[1]\n",
    "\n",
    "    return count, \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def invalid_minmax_df(df, key):\n",
    "    \"\"\"Ensures that min/max ranges are going in the right direction!\n",
    "    \n",
    "    Makes sure that the min/max columns of a distribution dataframe are\n",
    "    not larger than the other.  Should always return 0.  Used in debugging.\n",
    "    \"\"\"\n",
    "    return (~(df[key + '_min'] <= df[key + '_max'])).sum()\n",
    "\n",
    "def invert_redux(redux):\n",
    "    \"\"\"Inverts min/max\n",
    "    \n",
    "    Used for when a min/max value has an inverse relationship\n",
    "    with another min/max value\n",
    "    \"\"\"\n",
    "    if redux == \"min\":\n",
    "        return \"max\"\n",
    "    elif redux == \"max\":\n",
    "        return \"min\"\n",
    "    return redux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Either read a cached version of the file size distribution, or recalculate and cache it\n",
    "cached_histogram = INPUT_DB_FILE.replace('.sqlite', '_hist.csv')\n",
    "if os.path.isfile(cached_histogram):\n",
    "    print(\"Reading cached histogram from %s\" % cached_histogram)\n",
    "    reference_df = pandas.read_csv(cached_histogram, index_col='bin_size')\n",
    "else:\n",
    "    conn = sqlite3.connect(INPUT_DB_FILE)\n",
    "    print(\"Generating histogram from %s\" % INPUT_DB_FILE)\n",
    "    reference_df = histogram.histogram_dataframe(conn, INODE_TYPES)\n",
    "    conn.close()\n",
    "    print(\"Writing cached histogram to %s\" % cached_histogram)\n",
    "    reference_df.to_csv(cached_histogram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "REDUCTIONS = ('min', 'max', 'ave')\n",
    "reference_df['bin_extent_min'] = numpy.concatenate((numpy.array([0, 2]), reference_df.index[1:-1].values + 1))\n",
    "reference_df['bin_extent_max'] = reference_df.index.values\n",
    "reference_df['bin_extent_ave'] = (reference_df['bin_extent_min'] + reference_df['bin_extent_max']) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for itype in reference_df:\n",
    "    if itype.startswith('num_'):\n",
    "        print(\"%20s: %12d inodes, %8.2f %s\" % (itype,\n",
    "                                            reference_df[itype].sum(),\n",
    "                                            *(humanize_units((reference_df[itype] * reference_df['bin_extent_ave']).sum()))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate the mass distributions of data and metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_inode_mass(input_df, redux, minmax=None):\n",
    "    suffix = \"\"\n",
    "    if minmax:\n",
    "        suffix = \"_\" + minmax\n",
    "    # Assume all files have the same inode mass - LUSTRE_BYTES_PER_INODE\n",
    "    ret = input_df['num_files' + suffix] * LUSTRE_BYTES_PER_INODE\n",
    "    \n",
    "    # Now calculate the non-file inode masses with the constraint that all\n",
    "    # inodes must be _at least_ LUSTRE_BYTES_PER_INODE large\n",
    "    for itype in NON_FILE_INODE_TYPES:\n",
    "        _tmp_df = (input_df['num_%s%s' % (itype, suffix)] * reference_df['bin_extent_%s' % redux]).to_frame()\n",
    "        _tmp_df['_'] = (input_df['num_%s%s' % (itype, suffix)] * LUSTRE_BYTES_PER_INODE)\n",
    "        _tmp_df.max(axis=1)\n",
    "        ret += _tmp_df.max(axis=1)\n",
    "    \n",
    "    return ret.fillna(0.0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mass_dist = pandas.DataFrame(index=reference_df.index)\n",
    "\n",
    "for redux in REDUCTIONS:\n",
    "    # calculate data mass of each bin\n",
    "    mass_dist['dmass_%s' % redux] = (reference_df['num_files'] * reference_df['bin_extent_%s' % redux]).fillna(0.0)\n",
    "\n",
    "mass_dist.head() * TO_GIB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate mass probability distributions\n",
    "\n",
    "* $P_{dmass}$ is the mass distribution of file data\n",
    "* $P_{imass}$ is the mass distribution of metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate absolute mass distribution\n",
    "prob_dist = pandas.DataFrame(index=reference_df.index)\n",
    "\n",
    "# estimate the total file system mass from the estimated mass-per-bin\n",
    "mass_dist_sums = {'dmass_%s' % redux: mass_dist['dmass_%s' % redux].sum() for redux in REDUCTIONS}\n",
    "\n",
    "# Calculate the min/max/average probability distributions\n",
    "#   Note: the min probability dist is proportional to the max mass distribution sum\n",
    "#   because the mass distribution sum is in the denominator\n",
    "for redux in REDUCTIONS:\n",
    "    prob_dist[\"dmass_\" + redux] = mass_dist[\"dmass_\" + redux] / mass_dist_sums[\"dmass_\" + invert_redux(redux)]\n",
    "\n",
    "prob_dist.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visually check the probability distribution\n",
    "fig, ax = matplotlib.pyplot.subplots(figsize=(8, 4))\n",
    "prob_dist[['dmass_ave']].plot.bar(width=1.0, edgecolor='black', ax=ax)\n",
    "new_xticks = []\n",
    "for idx, xtick in enumerate(zip(ax.get_xticks(), ax.get_xticklabels())):\n",
    "    if idx % 6 == 0:\n",
    "        new_xticks.append((xtick[0], \"%d %s\" % humanize_units(int(xtick[1].get_text()))))\n",
    "_a, _b = zip(*new_xticks)\n",
    "ax.set_xticks(_a)\n",
    "ax.set_xticklabels(_b, ha='right', rotation=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate $M^{data}$\n",
    "\n",
    "Calculate the mass distribution of the new file system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_mass_dist = pandas.DataFrame(index=reference_df.index)\n",
    "\n",
    "# Calculate the min/max/average probability distributions\n",
    "for mass_type in 'dmass',:\n",
    "    for redux in REDUCTIONS:\n",
    "        new_mass_dist[mass_type + \"_\" + redux] = prob_dist[mass_type + '_' + redux] * TARGET_TOTAL_OST_CAPACITY\n",
    "\n",
    "new_mass_dist.head() * TO_GIB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate $N^{file}$\n",
    "\n",
    "Calculate the distribution of files for the new file system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert probability distribution into a new data mass distribution\n",
    "newfs_df = pandas.DataFrame(index=reference_df.index)\n",
    "\n",
    "# From the new mass distribution, calculate the number of files\n",
    "newfs_df['num_files_min'] = (new_mass_dist['dmass_min'] / reference_df['bin_extent_max']).fillna(0.0)\n",
    "newfs_df['num_files_max'] = (new_mass_dist['dmass_max'] / reference_df['bin_extent_min'].apply(lambda x: max(1, x))).fillna(0.0)\n",
    "newfs_df['num_files_ave'] = (new_mass_dist['dmass_ave'] / reference_df['bin_extent_ave']).fillna(0.0)\n",
    "\n",
    "newfs_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate $N$ for all inode types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From the new file distribution, calculate the number of other inode types\n",
    "for itype in NON_FILE_INODE_TYPES:\n",
    "    for redux in REDUCTIONS:\n",
    "        newfs_df['num_%s_%s' % (itype, redux)] = (newfs_df['num_files_' + redux] * reference_df['num_' + itype] / reference_df['num_files']).fillna(0.0)\n",
    "\n",
    "newfs_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From our new inode size distribution, calculate their mass\n",
    "inode_mass = {}\n",
    "for redux in REDUCTIONS:\n",
    "    # calculate inode mass of each bin\n",
    "    inode_mass[redux] = calculate_inode_mass(newfs_df, redux, minmax=redux)\n",
    "\n",
    "for key, val in inode_mass.items():\n",
    "    print(\"%5s %.2f GiB\" % (key, val * TO_GIB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for redux in []:# REDUCTIONS:\n",
    "    sum_file_count = newfs_df['num_files_' + redux].sum()\n",
    "    sum_file_mass = sum_file_count * 4096\n",
    "\n",
    "    sum_all_count = 0.0\n",
    "    for itype in INODE_TYPES:\n",
    "        colname = \"num_%s_%s\" % (itype, redux)\n",
    "        sum_all_count += newfs_df[colname].sum()\n",
    "    sum_all_mass = inode_mass[redux]\n",
    "\n",
    "    sum_nonfile_count = 0.0\n",
    "    for itype in NON_FILE_INODE_TYPES:\n",
    "        colname = \"num_%s_%s\" % (itype, redux)\n",
    "        sum_nonfile_count += newfs_df[colname].sum()\n",
    "    sum_nonfile_mass = sum_all_mass - sum_file_mass\n",
    "\n",
    "    print(\"  %3s mass required for %10d file inodes:     %5.1f %s\" % (\n",
    "        redux.title(),\n",
    "        sum_file_count,\n",
    "        *humanize_units(sum_file_mass)))\n",
    "    print(\"                        %10d non-file inodes: %5.1f %s\" % (\n",
    "        sum_nonfile_count,\n",
    "        *humanize_units(sum_nonfile_mass)))\n",
    "    print(\"                        %10d total inodes:    %5.1f %s\\n\" % (\n",
    "        sum_all_count,\n",
    "        *humanize_units(sum_all_mass)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate $C^{DOM}$\n",
    "\n",
    "Calculate the two contributions to DOM capacity usage on MDT:\n",
    "\n",
    "* whole small files\n",
    "* the first stripe of large files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_mdt = pandas.DataFrame(index=newfs_df.index)\n",
    "\n",
    "size_on_mdt = {\"first_stripe_mass_%s\" % redux: [] for redux in REDUCTIONS}\n",
    "size_on_mdt.update({\"whole_file_mass_%s\" % redux: [] for redux in REDUCTIONS})\n",
    "for iloc, row in enumerate(new_mass_dist.itertuples()):\n",
    "    for redux in REDUCTIONS:\n",
    "        # calculate contributions of small files wholly resident on MDT\n",
    "        size_on_mdt['whole_file_mass_' + redux].append(\n",
    "            new_mass_dist['dmass_%s' % redux].iloc[0:iloc+1].sum())\n",
    "\n",
    "        # calculate contributions of large files whose first stripe resides on MDT\n",
    "        size_on_mdt['first_stripe_mass_' + redux].append(\n",
    "            newfs_df['num_files_' + redux].iloc[iloc+1:].sum()\n",
    "            * reference_df['bin_extent_max'].iloc[iloc])\n",
    "\n",
    "for colname, elements in size_on_mdt.items():\n",
    "    new_mdt[colname] = elements\n",
    "\n",
    "for redux in REDUCTIONS:\n",
    "    new_mdt['total_dom_mass_' + redux] = new_mdt['whole_file_mass_' + redux] + new_mdt['first_stripe_mass_' + redux]\n",
    "\n",
    "new_mdt.applymap(lambda x: \"%.1f %s\" % humanize_units(x)).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the DoM capacity required for different layouts\n",
    "\n",
    "Note that the below plots start at 4 KiB which is below the minimum Lustre stripe size of 64 KiB at the time of writing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the amount of MDT capacity needed for different choices of PFL first-stripe size\n",
    "# with Data-on-MDT enabled\n",
    "def plot_dom_capacity(x, ymin, yave, ymax, ax=None, **kwargs):\n",
    "    if not ax:\n",
    "        fig, ax = matplotlib.pyplot.subplots(figsize=(8,6))\n",
    "        \n",
    "    if yave is not None:\n",
    "        ax.plot(x, yave, ls='-', label=\"Average\" if 'label' not in kwargs else kwargs.pop('label'), **kwargs)\n",
    "    if ymin is not None:\n",
    "        ax.plot(x, ymin, ls='--', label=\"Minimum\" if 'label' not in kwargs else kwargs.pop('label'), **kwargs)\n",
    "    if ymax is not None:\n",
    "        ax.plot(x, ymax, ls='--', label=\"Maximum\" if 'label' not in kwargs else kwargs.pop('label'), **kwargs)\n",
    "\n",
    "    ax.set_xscale(\"log\", basex=2)\n",
    "    ax.set_yscale(\"log\", basey=2)\n",
    "\n",
    "    ax.set_xlabel(\"Size of first stripe on MDT ($S_0$)\")\n",
    "    ax.set_ylabel(\"MDT capacity ($C^{MDT}$)\")\n",
    "\n",
    "    xticks = [2**x for x in range(12, 26, 2)]\n",
    "    ax.set_xlim(xticks[0] * 0.75, xticks[-1]*1.5)\n",
    "    ax.set_xticks(xticks)\n",
    "    ax.set_xticklabels([\"%d %s\" % humanize_units(x) for x in xticks], rotation=30, ha='right')\n",
    "\n",
    "    yticks = [2**x for x in range(42, 53, 1)]\n",
    "    ax.set_ylim(yticks[0] * 0.75, yticks[-1]*1.5)\n",
    "    ax.set_yticks(yticks)\n",
    "    ax.set_yticklabels([\"%d %s\" % humanize_units(y) for y in yticks])\n",
    "\n",
    "    ax.grid()\n",
    "    ax.set_axisbelow(True)\n",
    "\n",
    "    ax.set_title(\"Scaled to a %.1f %s file system\" % humanize_units(TARGET_TOTAL_OST_CAPACITY))\n",
    "    \n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = matplotlib.pyplot.subplots(figsize=(8, 5))\n",
    "\n",
    "plot_dom_capacity(x=new_mdt.index.values,\n",
    "                  ymin=new_mdt['total_dom_mass_min'].values + inode_mass['min'],\n",
    "                  yave=new_mdt['total_dom_mass_ave'].values + inode_mass['ave'],\n",
    "                  ymax=new_mdt['total_dom_mass_max'].values + inode_mass['max'],\n",
    "                  ax=ax,\n",
    "                  color='C2')\n",
    "\n",
    "ax.fill_between(\n",
    "    x=new_mdt.index.values,\n",
    "    y1=new_mdt['total_dom_mass_min'].values + inode_mass['min'],\n",
    "    y2=new_mdt['total_dom_mass_max'].values + inode_mass['max'],\n",
    "    color='C2',\n",
    "    alpha=0.25)\n",
    "\n",
    "# handles, labels = ax.get_legend_handles_labels()\n",
    "# labels[0] = \"Estimated\"\n",
    "# labels[1] = \"Min/max\"\n",
    "# ax.legend(handles=handles[0:2] + handles[3:5], labels=labels[0:2] + labels[3:5])\n",
    "ax.legend().set_visible(False)\n",
    "\n",
    "ax.set_title(\"\")\n",
    "ax.grid(b=True)\n",
    "ax.set_axisbelow(True)\n",
    "\n",
    "for line in ax.lines:\n",
    "    if line.get_linestyle() == \"--\":\n",
    "        line.set_visible(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = matplotlib.pyplot.subplots(figsize=(8, 5))\n",
    "\n",
    "ymin_dom = new_mdt['total_dom_mass_min']\n",
    "ymin_imass = pandas.Series(ymin_dom * 0 + inode_mass['min'], index=new_mdt.index)\n",
    "ymax_dom = new_mdt['total_dom_mass_max']\n",
    "ymax_imass = pandas.Series(ymax_dom * 0 + inode_mass['max'], index=new_mdt.index)\n",
    "\n",
    "ymin = ymin_dom + ymin_imass\n",
    "ymax = ymax_dom + ymax_imass\n",
    "yave = new_mdt['total_dom_mass_ave'] + inode_mass['ave']\n",
    "\n",
    "plot_dom_capacity(x=new_mdt.index.values,\n",
    "                  ymin=None,# ymin,\n",
    "                  yave=yave,\n",
    "                  ymax=None,# ymax,\n",
    "                  ax=ax,\n",
    "                  color='black',\n",
    "                  linewidth=1.5,\n",
    "                  label=\"\")\n",
    "\n",
    "# Plot components of uncertainty\n",
    "_delta = (inode_mass['max'] + inode_mass['min']) / 2\n",
    "\n",
    "ax.fill_between(\n",
    "    x=new_mdt.index.values,\n",
    "    y1=ymin,\n",
    "    y2=pandas.concat([yave - _delta, ymin], axis=1).max(axis=1),\n",
    "    color='C3',\n",
    "    alpha=0.25,\n",
    "    label=\"DOM uncertainty\")\n",
    "\n",
    "ax.fill_between(\n",
    "    x=new_mdt.index.values,\n",
    "    y1=pandas.concat([yave - _delta, ymin], axis=1).max(axis=1),\n",
    "    y2=yave,\n",
    "    color='C0',\n",
    "    alpha=0.25,\n",
    "    label=\"inode uncertainty\")\n",
    "\n",
    "ax.fill_between(\n",
    "    x=new_mdt.index.values,\n",
    "    y1=yave,\n",
    "    y2=yave + _delta,\n",
    "    color='C0',\n",
    "    alpha=0.25)\n",
    "ax.fill_between(\n",
    "    x=new_mdt.index.values,\n",
    "    y1=yave + _delta,\n",
    "    y2=ymax,\n",
    "    color='C3',\n",
    "    alpha=0.25)\n",
    "\n",
    "\n",
    "ax.legend()\n",
    "ax.set_title(\"\")\n",
    "ax.grid(b=True)\n",
    "ax.set_axisbelow(True)\n",
    "\n",
    "ax_plot = ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file = 'dom_capacity_required_%s.pdf' % INPUT_DB_DATE\n",
    "fig.savefig(output_file, dpi=200, bbox_inches='tight', transparent=True)\n",
    "print(\"Wrote output to\", output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xticks = [2**x for x in range(10, 38, 2)]\n",
    "ax_plot.set_xlim(xticks[0] * 0.75, xticks[-1]*1.5)\n",
    "ax_plot.set_xticks(xticks)\n",
    "ax_plot.set_xticklabels([\"%d %s\" % humanize_units(x) for x in xticks], rotation=30, ha='right')\n",
    "\n",
    "yticks = [2**x for x in range(42, 57)]\n",
    "ax_plot.set_ylim(yticks[0] * 0.75, yticks[-1]*1.5)\n",
    "ax_plot.set_yticks(yticks)\n",
    "ax_plot.set_yticklabels([\"%d %s\" % humanize_units(y) for y in yticks])\n",
    "\n",
    "ax_plot.get_figure()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file = 'dom_capacity_required_extended_%s.pdf' % INPUT_DB_DATE\n",
    "fig.savefig(output_file, dpi=200, bbox_inches='tight', transparent=True)\n",
    "print(\"Wrote output to\", output_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following plot breaks out the component contributions on the log scale to help visually show how each component of uncertainty contributes to the net uncertainty shown in the above figure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = matplotlib.pyplot.subplots(figsize=(8, 5))\n",
    "\n",
    "ymin_dom = new_mdt['total_dom_mass_min']\n",
    "ymin_imass = pandas.Series(ymin_dom * 0 + inode_mass['min'], index=new_mdt.index)\n",
    "ymax_dom = new_mdt['total_dom_mass_max']\n",
    "ymax_imass = pandas.Series(ymax_dom * 0 + inode_mass['max'], index=new_mdt.index)\n",
    "\n",
    "ymin = ymin_dom + ymin_imass\n",
    "ymax = ymax_dom + ymax_imass\n",
    "yave = new_mdt['total_dom_mass_ave'] + inode_mass['ave']\n",
    "\n",
    "plot_dom_capacity(x=new_mdt.index.values,\n",
    "                  ymin=None,# ymin,\n",
    "                  yave=yave,\n",
    "                  ymax=None,# ymax,\n",
    "                  ax=ax,\n",
    "                  color='C4')\n",
    "\n",
    "ax.plot(ymin_dom, color='C3')\n",
    "ax.plot(ymax_dom, color='C3')\n",
    "ax.plot(ymin_imass, color='C0')\n",
    "ax.plot(ymax_imass, color='C0')\n",
    "\n",
    "ax.legend()\n",
    "\n",
    "ax.set_title(\"\")\n",
    "ax.grid(b=True)\n",
    "ax.set_axisbelow(True)\n",
    "\n",
    "xticks = [2**x for x in range(10, 38, 2)]\n",
    "ax.set_xlim(xticks[0] * 0.75, xticks[-1]*1.5)\n",
    "ax.set_xticks(xticks)\n",
    "ax.set_xticklabels([\"%d %s\" % humanize_units(x) for x in xticks], rotation=30, ha='right')\n",
    "\n",
    "yticks = [2**x for x in range(39, 57)]\n",
    "ax.set_ylim(yticks[0] * 0.75, yticks[-1]*1.5)\n",
    "ax.set_yticks(yticks)\n",
    "ax.set_yticklabels([\"%d %s\" % humanize_units(y) for y in yticks])\n",
    "\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
