{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SSD Endurance Requirements\n",
    "\n",
    "This notebook demonstrates how we determine the minimum required drive endurance for the SSDs to be deployed in Perlmutter.  The master equation is\n",
    "\n",
    "$\n",
    "        {DWPD}^{new} =\n",
    "        {SSI}\n",
    "        \\cdot\n",
    "        {FSWPD}^{ref}\n",
    "        \\cdot\n",
    "        {WAF}\n",
    "        \\cdot\n",
    "        \\left ( \\frac{1}{\\chi} \\right )\n",
    "        \\left ( \\frac{N^{ref}}{N^{new}} \\right )\n",
    "        \\left ( \\frac{c^{ref}}{c^{new}} \\right )\n",
    "        \\left ( \\frac{R^{ref}}{R^{new}} \\right )\n",
    "$\n",
    "\n",
    "where\n",
    "\n",
    "- ${SSI}$ is the sustained system improvement\n",
    "- ${FSWPD}^{ref}$ is the reference file system's total write volume expressed in units of file system writes per day\n",
    "- ${WAF}$ is the write amplification factor that results from factors intrinsic to the application workload\n",
    "- $\\chi$ is the fraction of Lustre capacity available after formatting, typically ranging from 0.95 to 0.97\n",
    "- $N^{ref}$ and $N^{new}$ are the number of drives in the reference and new systems\n",
    "- $c^{ref}$ and $c^{new}$ are the per-drive capacities in the reference and new systems\n",
    "- $R^{ref}$ and $R^{new}$ are the code rates of the reference and new systems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "import numpy\n",
    "import matplotlib.pyplot\n",
    "import pandas\n",
    "\n",
    "matplotlib.rcParams['font.size'] = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pibs_to_pbs(pibs):\n",
    "    return pibs * 2**50 / 10**(5*3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "START_TIME = datetime.datetime(2017, 4, 1)\n",
    "END_TIME = datetime.datetime(2019, 3, 31)\n",
    "\n",
    "CSCRATCH_KIBS = 29763608416864 # from df -k\n",
    "CSCRATCH_BYTES = CSCRATCH_KIBS * 1024\n",
    "CSCRATCH_PIBS = CSCRATCH_BYTES / 2**50\n",
    "\n",
    "PARAM_SSI_LOW = 3.0\n",
    "PARAM_SSI_HIGH = 4.0\n",
    "\n",
    "PARAM_CHI = 0.95\n",
    "\n",
    "PARAM_N_REF = 248 * 41\n",
    "PARAM_C_REF = 4 * 10**(4*3) # in bytes\n",
    "PARAM_R_REF = 8.0 / (8.0 + 2.0)\n",
    "\n",
    "PARAM_N_NEW = None # unknown/undisclosed\n",
    "PARAM_C_NEW = None # unknown/undisclosed\n",
    "PARAM_R_NEW_LOW = 8.0 / (10.0 + 2.0)\n",
    "PARAM_R_NEW_HIGH = 8.0 / (8.0 + 2.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate FSWPD term\n",
    "\n",
    "We use daily I/O rates collected from LMT to determine the value for the $FSWPD$ parameter we will use in our endurance calculation here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cscratch_df = pandas.read_csv('datasets/cscratch_daily_iorates.csv')\n",
    "cscratch_df['date'] = [datetime.datetime.strptime(x, \"%Y-%m-%d\") for x in cscratch_df['date']]\n",
    "cscratch_df = cscratch_df[(cscratch_df['date'] >= START_TIME) & (cscratch_df['date'] <= END_TIME)]\n",
    "cscratch_df.index = cscratch_df['date']\n",
    "cscratch_df = cscratch_df.drop(columns=['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cscratch_df['fsrpd'] = cscratch_df['read_bytes'] / CSCRATCH_BYTES\n",
    "cscratch_df['fswpd'] = cscratch_df['write_bytes'] / CSCRATCH_BYTES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Distribution of FSWPD:\")\n",
    "print(cscratch_df['fswpd'].describe())\n",
    "\n",
    "print()\n",
    "\n",
    "print(\"Distribution of daily read+write volumes in TiB:\")\n",
    "print((cscratch_df['read_bytes'] + cscratch_df['write_bytes']).describe() / 2**40)\n",
    "\n",
    "print()\n",
    "\n",
    "print(\"Distribution of daily write volumes in TiB:\")\n",
    "print((cscratch_df['write_bytes']).describe() / 2**40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate the FSWPD distribution histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BINWIDTH = 0.0125\n",
    "fig, ax = matplotlib.pyplot.subplots(figsize=(8, 3.5))\n",
    "\n",
    "#cscratch_df['fswpd'].hist(edgecolor='black',\n",
    "#                          bins=numpy.arange(0, 0.3, BINWIDTH),\n",
    "#                          width=BINWIDTH * 0.8,\n",
    "#                          color='C0',\n",
    "#                          ax=ax,\n",
    "#                          density=True)\n",
    "\n",
    "hist, bins = numpy.histogram(cscratch_df['fswpd'],\n",
    "                             bins=numpy.arange(0, 0.3, BINWIDTH))\n",
    "\n",
    "ax.bar(bins[:-1],\n",
    "       hist.astype(numpy.float64) / hist.sum(),\n",
    "       width=BINWIDTH * 0.8,\n",
    "       color='C0',\n",
    "       edgecolor='black',\n",
    "       \n",
    "      )\n",
    "\n",
    "majtick = matplotlib.ticker.MultipleLocator(4*BINWIDTH)\n",
    "mintick = matplotlib.ticker.MultipleLocator(BINWIDTH)\n",
    "majtickfmt = matplotlib.ticker.FormatStrFormatter(\"%.2f\")\n",
    "ax.xaxis.set_major_locator(majtick)\n",
    "ax.xaxis.set_minor_locator(mintick)\n",
    "ax.xaxis.set_major_formatter(majtickfmt)\n",
    "ax.tick_params(which='major', length=7)\n",
    "\n",
    "ax.set_xlabel(\"File System Writes per Day\")\n",
    "#ax.set_ylabel(\"Number of days\")\n",
    "ax.set_ylabel(\"Fraction of days\")\n",
    "caption = \"Cori scratch (%.1f PB)\\n%s - %s\" % (\n",
    "    pibs_to_pbs(CSCRATCH_PIBS),\n",
    "    START_TIME.strftime(\"%b %-d, %Y\"),\n",
    "    END_TIME.strftime(\"%b %-d, %Y\"))\n",
    "ax.text(0.98, 0.78, caption, fontsize='medium',\n",
    "        ha='right', transform=ax.transAxes, backgroundcolor='#FFFFFFFF')\n",
    "\n",
    "ax.set_axisbelow(True)\n",
    "ax.xaxis.grid(False)\n",
    "\n",
    "\n",
    "if False:\n",
    "    ax.set_ylim(-10, None)\n",
    "    for bar in ax.patches:\n",
    "        x = bar.get_x()\n",
    "        y = bar.get_height()\n",
    "        if y > 0:\n",
    "    #       ax.text(x + 0.0115, y + 25, int(y), ha='center')\n",
    "            ax.text(x + BINWIDTH/2,\n",
    "                    #y + y * 2.0 + 15 if y < 100 else y + 75,\n",
    "                    y + 25,\n",
    "                    int(y),\n",
    "                    ha='center',\n",
    "                    rotation=90 if y >= 10 else 0,\n",
    "                    )\n",
    "\n",
    "num_annotations = 0\n",
    "for bar in ax.patches:\n",
    "    x = bar.get_x()\n",
    "    y = bar.get_height()\n",
    "    total = hist.sum()\n",
    "    ndays = y * total\n",
    "    if 0 < ndays < 10:\n",
    "        ax.annotate(\"%d day%s\" % (ndays, \"\" if ndays == 1 else \"s\"),\n",
    "                    xy=(x + BINWIDTH / 2, y + 0.01),\n",
    "                    xycoords='data',\n",
    "                    xytext=(0, 45),# + num_annotations * 10),\n",
    "                    textcoords='offset points',\n",
    "                    arrowprops={'facecolor': 'black', 'width': 1, \"headwidth\": 7, \"shrink\": 0.05},\n",
    "                    ha='center',\n",
    "                    va='bottom',\n",
    "                    rotation=90\n",
    "                   )\n",
    "        num_annotations += 1\n",
    "majtick = matplotlib.ticker.MultipleLocator(0.1)\n",
    "mintick = matplotlib.ticker.MultipleLocator(0.05)\n",
    "ax.yaxis.set_major_locator(majtick)\n",
    "ax.yaxis.set_minor_locator(mintick)\n",
    "ax.yaxis.grid()\n",
    "ax.set_ylim(-0.05, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file = 'cscratch_daily_iorates_%s-%s.pdf' % (START_TIME.strftime(\"%Y%m%d\"), END_TIME.strftime(\"%Y%m%d\"))\n",
    "fig.savefig(output_file, dpi=200, bbox_inches='tight', transparent=True)\n",
    "print(\"Wrote output to\", output_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pick a value for ${FSWPD}^{ref}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Report on extreme values\n",
    "PERCENTILE = 99\n",
    "\n",
    "print(\"%dth percentile is %.2f TiB written per day\" % (\n",
    "    PERCENTILE,\n",
    "    (cscratch_df['write_bytes'] / 2**40).quantile(q=PERCENTILE / 100.0)))\n",
    "\n",
    "print(\"%dth percentile is %.6f FSWPD\" % (\n",
    "    PERCENTILE, \n",
    "    cscratch_df['fswpd'].quantile(q=PERCENTILE / 100.0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PARAM_FSWPD = cscratch_df['fswpd'].mean()\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"Using %.3f as the value for FSWPD^ref\" % PARAM_FSWPD)\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate WAF term\n",
    "\n",
    "Here we calculate the write amplification factors of all SSDs in Cori's burst buffer to estimate the effect of misaligned writes has on SSD drives given Cori's production workload.\n",
    "\n",
    "This is a very imperfect analysis because\n",
    "\n",
    "1. Cori's burst buffer (DataWarp) does server-side write-back caching which can even out misaligned but sequential I/Os\n",
    "2. Cori's burst buffer has no parity, so there is no read-modify-write penalty\n",
    "3. Cori's burst buffer uses multilevel striping, and the four-SSD RAID0 configuration uses 512 KiB stripes\n",
    "4. Cori's burst buffer workload is not representative of the full Cori workload since only a small subset of NERSC users opts in to using the burst buffer\n",
    "\n",
    "But in the absence of both application-level write data to Lustre (provided by LMT) and device-level write data to disks (provided by smartctl or a RAID appliance), we can't calculate the true WAF.  Sadly, the vast majority of Cori's Lustre HDDs were affected by a firmware bug which caused them to stop reporting total bytes written."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_CSV = 'datasets/isdct_summary_20190401.csv'\n",
    "\n",
    "ssd_data = pandas.read_csv(INPUT_CSV)\n",
    "\n",
    "SSD_DATA_DATE = INPUT_CSV.rsplit('_', 1)[-1].split('.', 1)[0]\n",
    "\n",
    "BINWIDTH = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssd_data['waf'] = ssd_data['smart_nand_bytes_written_bytes'] / ssd_data['smart_host_bytes_written_bytes']\n",
    "ssd_data['lifetime_drive_writes'] = ssd_data['smart_host_bytes_written_bytes'] / (ssd_data['maximum_lba'] * 512) # 512 bytes per LBA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_waf_hist(ssd_data, ax=None):\n",
    "    if not ax:\n",
    "        fig, ax = matplotlib.pyplot.subplots(figsize=(8, 3.5))\n",
    "    else:\n",
    "        fig = ax.get_figure()\n",
    "\n",
    "    hist, bins = numpy.histogram(ssd_data['waf'],\n",
    "                                 bins=numpy.arange(0, 10 + 2*BINWIDTH, BINWIDTH))\n",
    "\n",
    "    ax.bar(bins[:-1] + BINWIDTH / 2,\n",
    "           hist.astype(numpy.float64) / hist.sum(),\n",
    "           width=BINWIDTH * 1.00,\n",
    "           color='C1',\n",
    "           edgecolor='black',\n",
    "\n",
    "          )\n",
    "\n",
    "#   majtick = matplotlib.ticker.MultipleLocator(2*BINWIDTH)\n",
    "#   mintick = matplotlib.ticker.MultipleLocator(BINWIDTH)\n",
    "#   majtickfmt = matplotlib.ticker.FormatStrFormatter(\"%d\")\n",
    "#   ax.xaxis.set_major_locator(majtick)\n",
    "#   ax.xaxis.set_minor_locator(mintick)\n",
    "#   ax.xaxis.set_major_formatter(majtickfmt)\n",
    "#   ax.tick_params(which='major', length=7)\n",
    "\n",
    "    ax.set_xlabel(\"Write Amplification Factor\")\n",
    "    #ax.set_ylabel(\"Number of days\")\n",
    "    ax.set_ylabel(\"Fraction of SSDs\")\n",
    "\n",
    "    ax.set_axisbelow(True)\n",
    "    ax.xaxis.grid(True)\n",
    "    \n",
    "    majtick = matplotlib.ticker.MultipleLocator(0.1)\n",
    "#   mintick = matplotlib.ticker.MultipleLocator(0.05)\n",
    "    ax.yaxis.set_major_locator(majtick)\n",
    "#   ax.yaxis.set_minor_locator(mintick)\n",
    "    ax.yaxis.grid()\n",
    "    ax.set_ylim(-0.05, None)\n",
    "\n",
    "    # annotate outliers\n",
    "    num_annotations = 0\n",
    "    for bar in ax.patches:\n",
    "        x = bar.get_x()\n",
    "        y = bar.get_height()\n",
    "        total = hist.sum()\n",
    "        ndays = y * total\n",
    "        if 0 < ndays < 20:\n",
    "            ax.annotate(\"%d drive%s\" % (ndays, \"\" if ndays == 1 else \"s\"),\n",
    "                        xy=(x + BINWIDTH / 2, y + 0.01),\n",
    "                        xycoords='data',\n",
    "                        xytext=(0, 45),# + num_annotations * 10),\n",
    "                        textcoords='offset points',\n",
    "                        arrowprops={'facecolor': 'black', 'width': 1, \"headwidth\": 7, \"shrink\": 0.05},\n",
    "                        ha='center',\n",
    "                        va='bottom',\n",
    "                        rotation=90\n",
    "                       )\n",
    "            num_annotations += 1\n",
    "\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_waf_scatter(ssd_data, ax=None):\n",
    "    \n",
    "    if not ax:\n",
    "        fig, ax = matplotlib.pyplot.subplots(figsize=(8, 3.5))\n",
    "    else:\n",
    "        fig = ax.get_figure()\n",
    "\n",
    "    x = ssd_data['waf']\n",
    "#   y = ssd_data['smart_host_bytes_written_bytes'] / 10**12\n",
    "    y = ssd_data['lifetime_drive_writes']\n",
    "\n",
    "    ax.scatter(x, y, marker='x', color='black', alpha=0.25)\n",
    "\n",
    "    ax.set_xlabel(\"WAF\")\n",
    "    ax.set_ylabel(\"Lifetime\\nDrive Writes\")\n",
    "    ax.grid()\n",
    "    ax.set_axisbelow(True)\n",
    "\n",
    "    majtick = matplotlib.ticker.MultipleLocator(2*BINWIDTH)\n",
    "#   mintick = matplotlib.ticker.MultipleLocator(BINWIDTH)\n",
    "    majtickfmt = matplotlib.ticker.FormatStrFormatter(\"%d\")\n",
    "    ax.xaxis.set_major_locator(majtick)\n",
    "#   ax.xaxis.set_minor_locator(mintick)\n",
    "    ax.xaxis.set_major_formatter(majtickfmt)\n",
    "    ax.tick_params(which='major', length=7)\n",
    "    \n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = matplotlib.pyplot.subplots(nrows=2, ncols=1, figsize=(8, 6), sharex=True)\n",
    "fig.subplots_adjust(hspace=0.0, wspace=0.0)\n",
    "\n",
    "plot_waf_hist(ssd_data, ax=axes[0])\n",
    "plot_waf_scatter(ssd_data, ax=axes[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plot_waf_hist(ssd_data)\n",
    "output_file = 'coribb_ssd_wafs_hist_%s.pdf' % SSD_DATA_DATE\n",
    "ax.get_figure().savefig(output_file, dpi=200, bbox_inches='tight', transparent=True)\n",
    "print(\"Wrote output to\", output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file = 'coribb_ssd_wafs_%s.pdf' % SSD_DATA_DATE\n",
    "fig.savefig(output_file, dpi=200, bbox_inches='tight', transparent=True)\n",
    "print(\"Wrote output to\", output_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pick a value for WAF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Distribution of years in service:\")\n",
    "print((ssd_data['power_on_hours'] / 24 / 365.25).describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Distribution of WAFs:\")\n",
    "(ssd_data['waf']).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PERCENTILE_LOW = 50\n",
    "PERCENTILE_HIGH = 95\n",
    "\n",
    "print(\"%2dth percentile: %.2f\" % (PERCENTILE_LOW, ssd_data['waf'].quantile(q=PERCENTILE_LOW / 100.0)))\n",
    "print(\"%2dth percentile: %.2f \" % (PERCENTILE_HIGH, ssd_data['waf'].quantile(q=PERCENTILE_HIGH / 100.0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PARAM_WAF_LOW = ssd_data['waf'].quantile(q=PERCENTILE_LOW / 100.0)\n",
    "PARAM_WAF_HIGH = ssd_data['waf'].quantile(q=PERCENTILE_HIGH / 100.0)\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"Using %.2f as the value for WAF_low\" % PARAM_WAF_LOW)\n",
    "print(\"Using %.2f as the value for WAF_high\" % PARAM_WAF_HIGH)\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate DWPD\n",
    "\n",
    "We can finally calculate $DWPD$ using\n",
    "\n",
    "> $\n",
    "        {DWPD}^{new} =\n",
    "        {SSI}\n",
    "        \\cdot\n",
    "        {FSWPD}^{ref}\n",
    "        \\cdot\n",
    "        {WAF}\n",
    "        \\cdot\n",
    "        \\left ( \\frac{1}{\\chi} \\right )\n",
    "        \\left ( \\frac{N^{ref}}{N^{new}} \\right )\n",
    "        \\left ( \\frac{c^{ref}}{c^{new}} \\right )\n",
    "        \\left ( \\frac{R^{ref}}{R^{new}} \\right )\n",
    "$\n",
    "\n",
    "Note that we actually use the form\n",
    "\n",
    "> $\n",
    "        {DWPD}^{new} =\n",
    "        {SSI}\n",
    "        \\cdot\n",
    "        {FSWPD}^{ref}\n",
    "        \\cdot\n",
    "        {WAF}\n",
    "        \\cdot\n",
    "        \\left ( \\frac{N^{ref} \\cdot c^{ref} \\cdot R^{ref}}{C^{new}} \\right )\n",
    "$\n",
    "\n",
    "where $C^{new}$ is defined either as\n",
    "\n",
    "- $C^{new} = \\chi \\cdot R \\cdot N^{new} \\cdot c^{new}$, if we know what $c^{new}$ and $N^{new}$ will be on our new file system, or\n",
    "- $C^{new} = SSI \\cdot \\left ( \\frac{ \\lambda_{purge}}{{PF}} \\right ) \\cdot \\left ( \\frac{\\partial C^{ref}}{\\partial t} \\right )$, which is how we determined the minimum required capacity for the new file system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if None in (PARAM_CHI, PARAM_N_NEW, PARAM_C_NEW, PARAM_R_NEW_LOW, PARAM_R_NEW_HIGH):\n",
    "    # these are the file system capacity requirements from cscratch_daily_growth.ipynb\n",
    "    # daily_fill_pct.mean() * CSCRATCH_KIBS * 1024 = 133116697694451.58 bytes/day = 133 TB/day \n",
    "    print(\"NOTE: deriving chi * R * N * c from C^new because chi, R, N, or c is undefined!\\n\")\n",
    "    PARAM_BIGC_NEW_LOW = PARAM_SSI_LOW * 28 / 0.5 * 133116697694451.58\n",
    "    PARAM_BIGC_NEW_HIGH = PARAM_SSI_HIGH * 28 / 0.5 * 133116697694451.58\n",
    "else:\n",
    "    PARAM_BIGC_NEW_LOW = PARAM_CHI * PARAM_R_NEW_LOW * PARAM_N_NEW * PARAM_C_NEW\n",
    "    PARAM_BIGC_NEW_HIGH = PARAM_CHI * PARAM_R_NEW_HIGH * PARAM_N_NEW * PARAM_C_NEW\n",
    "\n",
    "print(\"Using chi * (R * N * c)^new = %.0f PB (low)\" % (PARAM_BIGC_NEW_LOW / 10**(5*3)))\n",
    "print(\"                            = %.0f PB (high)\" % (PARAM_BIGC_NEW_HIGH / 10**(5*3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DWPD_NEW_LOW = PARAM_SSI_LOW * PARAM_FSWPD * PARAM_WAF_LOW * PARAM_R_REF * PARAM_N_REF * PARAM_C_REF / PARAM_BIGC_NEW_LOW\n",
    "DWPD_NEW_HIGH = PARAM_SSI_HIGH * PARAM_FSWPD * PARAM_WAF_HIGH * PARAM_R_REF * PARAM_N_REF * PARAM_C_REF / PARAM_BIGC_NEW_HIGH\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"Required DWPD: %.2f (low)\" % DWPD_NEW_LOW)\n",
    "print(\"               %.2f (high)\" % DWPD_NEW_HIGH)\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
